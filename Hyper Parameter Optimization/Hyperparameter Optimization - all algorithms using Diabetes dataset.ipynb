{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b84b860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6bd178a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, cross_val_score\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials  #bayesian optimization\n",
    "from tpot import TPOTClassifier #genetic algorithms optimization\n",
    "import optuna #to optimize hyperparameters of the model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import sklearn.svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38530198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf95f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('diabetes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7028ead4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66</td>\n",
       "      <td>29.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6    148.0             72           35.0     30.5  33.6   \n",
       "1            1     85.0             66           29.0     30.5  26.6   \n",
       "2            8    183.0             64           23.0     30.5  23.3   \n",
       "3            1     89.0             66           23.0     94.0  28.1   \n",
       "4            0    137.0             40           35.0    168.0  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Glucose'] = np.where(df['Glucose']==0,df['Glucose'].median(),df['Glucose'])\n",
    "df['Insulin'] = np.where(df['Insulin']==0,df['Insulin'].median(),df['Insulin'])\n",
    "df['SkinThickness'] = np.where(df['SkinThickness']==0,df['SkinThickness'].median(),df['SkinThickness'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8681615",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Outcome',axis=1)\n",
    "y = df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b8b236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.20,random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4944b78b",
   "metadata": {},
   "source": [
    "## normally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f178d517",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=10)\n",
    "rf.fit(x_train,y_train)\n",
    "y_predict = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96300f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "360ada22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83 16]\n",
      " [30 25]]\n",
      "0.7012987012987013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78        99\n",
      "           1       0.61      0.45      0.52        55\n",
      "\n",
      "    accuracy                           0.70       154\n",
      "   macro avg       0.67      0.65      0.65       154\n",
      "weighted avg       0.69      0.70      0.69       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_predict))\n",
    "print(accuracy_score(y_test,y_predict))\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45f0a94",
   "metadata": {},
   "source": [
    "## by applying some parameters by choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e305886d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87 12]\n",
      " [28 27]]\n",
      "0.7402597402597403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.81        99\n",
      "           1       0.69      0.49      0.57        55\n",
      "\n",
      "    accuracy                           0.74       154\n",
      "   macro avg       0.72      0.68      0.69       154\n",
      "weighted avg       0.73      0.74      0.73       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc1 = RandomForestClassifier(n_estimators=500,criterion='gini',max_features='sqrt',min_samples_leaf=10,random_state=100)\n",
    "rfc1.fit(x_train,y_train)\n",
    "y_predict = rfc1.predict(x_test)\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "print(accuracy_score(y_test,y_predict))\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a65d90",
   "metadata": {},
   "source": [
    "## RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66a6effc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['sqrt', 'auto', 'log2'], 'max_depth': [10, 120, 230, 340, 450, 560, 670, 780, 890, 1000], 'min_samples_split': [1, 3, 4, 5, 7, 9], 'min_samples_leaf': [1, 2, 4, 6, 8], 'criterion': ['entropy', 'gini']}\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(200,2000,10)]\n",
    "max_features = ['sqrt','auto','log2']\n",
    "max_depth = [int(x) for x in np.linspace(10,1000,10)]\n",
    "min_samples_split = [1,3,4,5,7,9]\n",
    "min_samples_leaf = [1,2,4,6,8]\n",
    "\n",
    "random_grid = {'n_estimators':n_estimators,'max_features':max_features,'max_depth':max_depth,\n",
    "              'min_samples_split':min_samples_split,'min_samples_leaf':min_samples_leaf,\n",
    "              'criterion':['entropy','gini']}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17e52c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=sqrt, min_samples_leaf=8, min_samples_split=1, n_estimators=200; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=670, max_features=sqrt, min_samples_leaf=8, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=log2, min_samples_leaf=1, min_samples_split=7, n_estimators=1600; total time=   3.6s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=log2, min_samples_leaf=1, min_samples_split=7, n_estimators=1600; total time=   3.5s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=auto, min_samples_leaf=2, min_samples_split=9, n_estimators=2000; total time=   4.2s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=auto, min_samples_leaf=2, min_samples_split=9, n_estimators=2000; total time=   4.2s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   4.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=2000; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=sqrt, min_samples_leaf=2, min_samples_split=7, n_estimators=1000; total time=   2.1s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=sqrt, min_samples_leaf=2, min_samples_split=7, n_estimators=1000; total time=   2.0s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=auto, min_samples_leaf=6, min_samples_split=9, n_estimators=1000; total time=   2.0s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=auto, min_samples_leaf=6, min_samples_split=9, n_estimators=1000; total time=   2.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=log2, min_samples_leaf=4, min_samples_split=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=log2, min_samples_leaf=4, min_samples_split=7, n_estimators=200; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=120, max_features=sqrt, min_samples_leaf=6, min_samples_split=1, n_estimators=600; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=120, max_features=sqrt, min_samples_leaf=6, min_samples_split=1, n_estimators=600; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=log2, min_samples_leaf=2, min_samples_split=7, n_estimators=1400; total time=   3.2s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=log2, min_samples_leaf=2, min_samples_split=7, n_estimators=1400; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=670, max_features=sqrt, min_samples_leaf=8, min_samples_split=1, n_estimators=1400; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=670, max_features=sqrt, min_samples_leaf=8, min_samples_split=1, n_estimators=1400; total time=   0.7s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1400; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1400; total time=   3.3s\n",
      "[CV] END criterion=gini, max_depth=450, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=   5.0s\n",
      "[CV] END criterion=gini, max_depth=450, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1600; total time=   4.9s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=600; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=600; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=600; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=600; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1000; total time=   3.1s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1000; total time=   2.9s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=auto, min_samples_leaf=6, min_samples_split=9, n_estimators=1800; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=auto, min_samples_leaf=6, min_samples_split=9, n_estimators=1800; total time=   5.1s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=auto, min_samples_leaf=1, min_samples_split=9, n_estimators=600; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=auto, min_samples_leaf=1, min_samples_split=9, n_estimators=600; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=1, n_estimators=800; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=1, n_estimators=800; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=670, max_features=auto, min_samples_leaf=2, min_samples_split=1, n_estimators=2000; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=670, max_features=auto, min_samples_leaf=2, min_samples_split=1, n_estimators=2000; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time=   2.3s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=9, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=9, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1600; total time=   4.9s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1600; total time=   5.0s\n",
      "[CV] END criterion=entropy, max_depth=340, max_features=auto, min_samples_leaf=6, min_samples_split=5, n_estimators=800; total time=   2.3s\n",
      "[CV] END criterion=entropy, max_depth=340, max_features=auto, min_samples_leaf=6, min_samples_split=5, n_estimators=800; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=780, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=400; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=780, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=400; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=450, max_features=auto, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=450, max_features=auto, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=sqrt, min_samples_leaf=1, min_samples_split=7, n_estimators=800; total time=   2.2s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=sqrt, min_samples_leaf=1, min_samples_split=7, n_estimators=800; total time=   2.4s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=auto, min_samples_leaf=6, min_samples_split=5, n_estimators=2000; total time=   5.6s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=auto, min_samples_leaf=6, min_samples_split=5, n_estimators=2000; total time=   5.5s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=log2, min_samples_leaf=8, min_samples_split=9, n_estimators=1200; total time=   3.4s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=log2, min_samples_leaf=8, min_samples_split=9, n_estimators=1200; total time=   3.5s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=log2, min_samples_leaf=1, min_samples_split=9, n_estimators=1600; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=log2, min_samples_leaf=1, min_samples_split=9, n_estimators=1600; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=450, max_features=auto, min_samples_leaf=4, min_samples_split=9, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=450, max_features=auto, min_samples_leaf=4, min_samples_split=9, n_estimators=200; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=890, max_features=sqrt, min_samples_leaf=6, min_samples_split=1, n_estimators=1400; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=890, max_features=sqrt, min_samples_leaf=6, min_samples_split=1, n_estimators=1400; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=8, min_samples_split=7, n_estimators=2000; total time=   6.1s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=8, min_samples_split=7, n_estimators=2000; total time=   6.0s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=800; total time=   2.2s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=800; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=230, max_features=log2, min_samples_leaf=4, min_samples_split=1, n_estimators=1400; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=230, max_features=log2, min_samples_leaf=4, min_samples_split=1, n_estimators=1400; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1000; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=890, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1000; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=log2, min_samples_leaf=8, min_samples_split=5, n_estimators=400; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=log2, min_samples_leaf=8, min_samples_split=5, n_estimators=400; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=340, max_features=sqrt, min_samples_leaf=8, min_samples_split=9, n_estimators=600; total time=   1.7s\n",
      "[CV] END criterion=entropy, max_depth=340, max_features=sqrt, min_samples_leaf=8, min_samples_split=9, n_estimators=600; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=log2, min_samples_leaf=4, min_samples_split=7, n_estimators=1600; total time=   5.0s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=log2, min_samples_leaf=4, min_samples_split=7, n_estimators=1600; total time=   4.6s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=auto, min_samples_leaf=1, min_samples_split=7, n_estimators=2000; total time=   6.1s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=auto, min_samples_leaf=1, min_samples_split=7, n_estimators=2000; total time=   6.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=6, min_samples_split=4, n_estimators=1400; total time=   4.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=6, min_samples_split=4, n_estimators=1400; total time=   4.3s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=auto, min_samples_leaf=6, min_samples_split=5, n_estimators=600; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=auto, min_samples_leaf=6, min_samples_split=5, n_estimators=600; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=1000, max_features=auto, min_samples_leaf=2, min_samples_split=1, n_estimators=1400; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=1000, max_features=auto, min_samples_leaf=2, min_samples_split=1, n_estimators=1400; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=log2, min_samples_leaf=4, min_samples_split=9, n_estimators=1000; total time=   3.4s\n",
      "[CV] END criterion=entropy, max_depth=780, max_features=log2, min_samples_leaf=4, min_samples_split=9, n_estimators=1000; total time=   3.1s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=log2, min_samples_leaf=6, min_samples_split=9, n_estimators=1800; total time=   5.3s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=log2, min_samples_leaf=6, min_samples_split=9, n_estimators=1800; total time=   5.3s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=400; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=400; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=7, n_estimators=2000; total time=   6.2s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=7, n_estimators=2000; total time=   6.0s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=400; total time=   1.2s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=400; total time=   1.2s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=600; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=600; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=6, min_samples_split=1, n_estimators=1800; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=6, min_samples_split=1, n_estimators=1800; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=1, n_estimators=600; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=1, n_estimators=600; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=sqrt, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=780, max_features=sqrt, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=auto, min_samples_leaf=6, min_samples_split=4, n_estimators=2000; total time=   5.8s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=auto, min_samples_leaf=6, min_samples_split=4, n_estimators=2000; total time=   5.9s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=log2, min_samples_leaf=6, min_samples_split=4, n_estimators=1200; total time=   3.4s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=log2, min_samples_leaf=6, min_samples_split=4, n_estimators=1200; total time=   3.7s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=log2, min_samples_leaf=2, min_samples_split=7, n_estimators=600; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=log2, min_samples_leaf=2, min_samples_split=7, n_estimators=600; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1600; total time=   5.0s\n",
      "[CV] END criterion=entropy, max_depth=450, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1600; total time=   5.4s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=log2, min_samples_leaf=4, min_samples_split=7, n_estimators=1600; total time=   5.3s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=log2, min_samples_leaf=4, min_samples_split=7, n_estimators=1600; total time=   4.9s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=log2, min_samples_leaf=4, min_samples_split=9, n_estimators=2000; total time=   5.9s\n",
      "[CV] END criterion=gini, max_depth=780, max_features=log2, min_samples_leaf=4, min_samples_split=9, n_estimators=2000; total time=   6.0s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1600; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1600; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=450, max_features=log2, min_samples_leaf=8, min_samples_split=7, n_estimators=1800; total time=   5.1s\n",
      "[CV] END criterion=gini, max_depth=450, max_features=log2, min_samples_leaf=8, min_samples_split=7, n_estimators=1800; total time=   5.1s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=log2, min_samples_leaf=1, min_samples_split=7, n_estimators=1000; total time=   3.0s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=log2, min_samples_leaf=1, min_samples_split=7, n_estimators=1000; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=800; total time=   2.4s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=800; total time=   2.5s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=log2, min_samples_leaf=8, min_samples_split=9, n_estimators=1600; total time=   4.8s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=log2, min_samples_leaf=8, min_samples_split=9, n_estimators=1600; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=1000, max_features=sqrt, min_samples_leaf=4, min_samples_split=1, n_estimators=800; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=1000, max_features=sqrt, min_samples_leaf=4, min_samples_split=1, n_estimators=800; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=1, n_estimators=600; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=1, n_estimators=600; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=340, max_features=auto, min_samples_leaf=8, min_samples_split=7, n_estimators=1400; total time=   4.2s\n",
      "[CV] END criterion=entropy, max_depth=340, max_features=auto, min_samples_leaf=8, min_samples_split=7, n_estimators=1400; total time=   3.9s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=log2, min_samples_leaf=6, min_samples_split=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=log2, min_samples_leaf=6, min_samples_split=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=sqrt, min_samples_leaf=8, min_samples_split=9, n_estimators=600; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=sqrt, min_samples_leaf=8, min_samples_split=9, n_estimators=600; total time=   1.5s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=9, n_estimators=2000; total time=   6.0s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=9, n_estimators=2000; total time=   5.9s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=auto, min_samples_leaf=4, min_samples_split=3, n_estimators=1800; total time=   5.1s\n",
      "[CV] END criterion=gini, max_depth=560, max_features=auto, min_samples_leaf=4, min_samples_split=3, n_estimators=1800; total time=   5.0s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=7, n_estimators=2000; total time=   6.0s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=7, n_estimators=2000; total time=   6.1s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=   5.3s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1800; total time=   5.2s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=sqrt, min_samples_leaf=6, min_samples_split=7, n_estimators=1000; total time=   2.8s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=sqrt, min_samples_leaf=6, min_samples_split=7, n_estimators=1000; total time=   2.8s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, n_estimators=600; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, n_estimators=600; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=400; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=120, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=400; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=auto, min_samples_leaf=1, min_samples_split=3, n_estimators=1800; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=auto, min_samples_leaf=1, min_samples_split=3, n_estimators=1800; total time=   5.2s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=auto, min_samples_leaf=2, min_samples_split=9, n_estimators=1000; total time=   3.0s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=auto, min_samples_leaf=2, min_samples_split=9, n_estimators=1000; total time=   2.8s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=log2, min_samples_leaf=4, min_samples_split=7, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=log2, min_samples_leaf=4, min_samples_split=7, n_estimators=200; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=560, max_features=auto, min_samples_leaf=2, min_samples_split=1, n_estimators=400; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=560, max_features=auto, min_samples_leaf=2, min_samples_split=1, n_estimators=400; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=log2, min_samples_leaf=8, min_samples_split=7, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=log2, min_samples_leaf=8, min_samples_split=7, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=340, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=1800; total time=   5.5s\n",
      "[CV] END criterion=entropy, max_depth=340, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=1800; total time=   5.0s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=auto, min_samples_leaf=1, min_samples_split=9, n_estimators=1000; total time=   3.1s\n",
      "[CV] END criterion=entropy, max_depth=1000, max_features=auto, min_samples_leaf=1, min_samples_split=9, n_estimators=1000; total time=   2.9s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=log2, min_samples_leaf=6, min_samples_split=4, n_estimators=400; total time=   1.2s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=log2, min_samples_leaf=6, min_samples_split=4, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=7, n_estimators=1800; total time=   5.5s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=auto, min_samples_leaf=1, min_samples_split=7, n_estimators=1800; total time=   5.6s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=2000; total time=   5.7s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=2000; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=auto, min_samples_leaf=6, min_samples_split=9, n_estimators=2000; total time=   5.8s\n",
      "[CV] END criterion=entropy, max_depth=670, max_features=auto, min_samples_leaf=6, min_samples_split=9, n_estimators=2000; total time=   5.9s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=log2, min_samples_leaf=6, min_samples_split=7, n_estimators=1400; total time=   4.1s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=log2, min_samples_leaf=6, min_samples_split=7, n_estimators=1400; total time=   4.2s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1200; total time=   3.5s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1200; total time=   3.6s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=auto, min_samples_leaf=2, min_samples_split=7, n_estimators=2000; total time=   5.9s\n",
      "[CV] END criterion=entropy, max_depth=560, max_features=auto, min_samples_leaf=2, min_samples_split=7, n_estimators=2000; total time=   6.0s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=7, n_estimators=400; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=7, n_estimators=400; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=1600; total time=   4.9s\n",
      "[CV] END criterion=entropy, max_depth=230, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=1600; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=1, n_estimators=2000; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=1, n_estimators=2000; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1600; total time=   4.9s\n",
      "[CV] END criterion=gini, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1600; total time=   4.6s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=120, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=7, n_estimators=600; total time=   1.7s\n",
      "[CV] END criterion=entropy, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=7, n_estimators=600; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=340, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=auto, min_samples_leaf=8, min_samples_split=3, n_estimators=1600; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=670, max_features=auto, min_samples_leaf=8, min_samples_split=3, n_estimators=1600; total time=   4.1s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=1600; total time=   4.8s\n",
      "[CV] END criterion=gini, max_depth=230, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=1600; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHY\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.7752443  0.77035831 0.77361564 0.76547231 0.77361564\n",
      " 0.77035831        nan 0.77850163 0.7752443         nan 0.76547231\n",
      " 0.78013029 0.77035831 0.77035831 0.7752443  0.77361564 0.76547231\n",
      "        nan        nan 0.76872964 0.77850163 0.76547231 0.77687296\n",
      "        nan        nan 0.77198697 0.7752443  0.77035831 0.7752443\n",
      " 0.77198697        nan 0.77198697 0.76872964        nan 0.77361564\n",
      " 0.77198697 0.77035831 0.77850163 0.76384365 0.77361564 0.77361564\n",
      "        nan 0.78013029 0.77035831 0.77850163 0.76710098 0.77198697\n",
      " 0.76872964 0.7752443         nan        nan        nan 0.77687296\n",
      " 0.77361564 0.7752443  0.76872964 0.78175896 0.78013029 0.77035831\n",
      " 0.77035831 0.77361564 0.77035831 0.77850163        nan        nan\n",
      " 0.77035831 0.77687296 0.77198697 0.77198697 0.77035831 0.78013029\n",
      " 0.77198697 0.76710098 0.77361564 0.76547231 0.76221498 0.76710098\n",
      " 0.77035831 0.76872964        nan 0.77035831 0.77198697 0.76710098\n",
      " 0.77198697 0.76872964 0.77687296 0.77361564 0.76710098 0.77198697\n",
      " 0.77198697 0.77361564 0.77198697        nan 0.7752443  0.77035831\n",
      " 0.7752443  0.77361564 0.77198697 0.76872964]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=1,\n",
       "                   param_distributions={'criterion': ['entropy', 'gini'],\n",
       "                                        'max_depth': [10, 120, 230, 340, 450,\n",
       "                                                      560, 670, 780, 890,\n",
       "                                                      1000],\n",
       "                                        'max_features': ['sqrt', 'auto',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4, 6, 8],\n",
       "                                        'min_samples_split': [1, 3, 4, 5, 7, 9],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=100, verbose=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rs_cv = RandomizedSearchCV(estimator=rfc,param_distributions=random_grid,n_iter=100,cv=2,verbose=2,random_state=100,n_jobs=1)\n",
    "rs_cv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "188c7ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1600,\n",
       " 'min_samples_split': 7,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'log2',\n",
       " 'max_depth': 120,\n",
       " 'criterion': 'entropy'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "feccbf01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=1,\n",
       "                   param_distributions={'criterion': ['entropy', 'gini'],\n",
       "                                        'max_depth': [10, 120, 230, 340, 450,\n",
       "                                                      560, 670, 780, 890,\n",
       "                                                      1000],\n",
       "                                        'max_features': ['sqrt', 'auto',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4, 6, 8],\n",
       "                                        'min_samples_split': [1, 3, 4, 5, 7, 9],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=100, verbose=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f95282f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=120, max_features='log2',\n",
       "                       min_samples_leaf=4, min_samples_split=7,\n",
       "                       n_estimators=1600)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3cc0af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85 14]\n",
      " [24 31]]\n",
      "0.7532467532467533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82        99\n",
      "           1       0.69      0.56      0.62        55\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.71      0.72       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_random_grid = rs_cv.best_estimator_\n",
    "y_predict = best_random_grid.predict(x_test)\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "print(accuracy_score(y_test,y_predict))\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eb790a",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41184b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1600,\n",
       " 'min_samples_split': 7,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'log2',\n",
       " 'max_depth': 120,\n",
       " 'criterion': 'entropy'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f40e36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': ['entropy'], 'max_depth': [120], 'max_features': ['log2'], 'min_samples_leaf': [4, 6, 8], 'min_samples_split': [6, 5, 7, 8, 9], 'n_estimators': [1400, 1500, 1600, 1700, 1800]}\n"
     ]
    }
   ],
   "source": [
    "para_grid = {'criterion':[rs_cv.best_params_['criterion']],'max_depth':[rs_cv.best_params_['max_depth']],\n",
    "             'max_features':[rs_cv.best_params_['max_features']],\n",
    "            'min_samples_leaf':[rs_cv.best_params_['min_samples_leaf'],\n",
    "                                rs_cv.best_params_['min_samples_leaf']+2,\n",
    "                                rs_cv.best_params_['min_samples_leaf']+4],\n",
    "            'min_samples_split':[rs_cv.best_params_['min_samples_split']-1,\n",
    "                                rs_cv.best_params_['min_samples_split']-2,\n",
    "                                rs_cv.best_params_['min_samples_split'],\n",
    "                                rs_cv.best_params_['min_samples_split']+1,\n",
    "                                rs_cv.best_params_['min_samples_split']+2],\n",
    "            'n_estimators':[rs_cv.best_params_['n_estimators']-200,\n",
    "                               rs_cv.best_params_['n_estimators']-100,\n",
    "                               rs_cv.best_params_['n_estimators'],\n",
    "                               rs_cv.best_params_['n_estimators']+100,\n",
    "                               rs_cv.best_params_['n_estimators']+200]}\n",
    "print(para_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5c1f3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1*1*1*3*5*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "664d41a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 75 candidates, totalling 750 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['entropy'], 'max_depth': [120],\n",
       "                         'max_features': ['log2'],\n",
       "                         'min_samples_leaf': [4, 6, 8],\n",
       "                         'min_samples_split': [6, 5, 7, 8, 9],\n",
       "                         'n_estimators': [1400, 1500, 1600, 1700, 1800]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "gs_cv = GridSearchCV(estimator=rfc,param_grid=para_grid,cv=10,n_jobs=-1,verbose=2)\n",
    "gs_cv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "090b359b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1*1*1*2*3*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a40e62ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=120, max_features='log2',\n",
       "                       min_samples_leaf=6, min_samples_split=9,\n",
       "                       n_estimators=1400)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec838742",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid = gs_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b82247b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[86 13]\n",
      " [25 30]]\n",
      "0.7532467532467533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.87      0.82        99\n",
      "           1       0.70      0.55      0.61        55\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.74      0.71      0.72       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict = best_grid.predict(x_test)\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "print(accuracy_score(y_test,y_predict))\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c77547",
   "metadata": {},
   "source": [
    "# Automated Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361bc10a",
   "metadata": {},
   "source": [
    "## Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8de4807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': <hyperopt.pyll.base.Apply at 0x295328474f0>,\n",
       " 'max_depth': <hyperopt.pyll.base.Apply at 0x295328474c0>,\n",
       " 'max_features': <hyperopt.pyll.base.Apply at 0x29532847520>,\n",
       " 'min_samples_leaf': <hyperopt.pyll.base.Apply at 0x295334d5c70>,\n",
       " 'min_samples_split': <hyperopt.pyll.base.Apply at 0x295334d5b50>,\n",
       " 'n_estimators': <hyperopt.pyll.base.Apply at 0x29532eeeac0>}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space = {'criterion':hp.choice('criterion',['entropy','gini']),\n",
    "        'max_depth':hp.quniform('max_depth',10,1200,10),\n",
    "        'max_features':hp.choice('max_features',['auto','sqrt','log2',None]),\n",
    "        'min_samples_leaf':hp.uniform('min_samples_leaf',0,0.5),\n",
    "        'min_samples_split':hp.uniform('min_samples_split',0,1),\n",
    "        'n_estimators':hp.choice('n_estimators',[10,50,300,750,1200,1300])}\n",
    "space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca4be23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hyperopt.pyll.base.Apply at 0x29532847520>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space['max_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5708a646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    model = RandomForestClassifier(criterion=space['criterion'],max_depth=space['max_depth'],\n",
    "                                  max_features=space['max_features'],min_samples_leaf=space['min_samples_leaf'],\n",
    "                                  min_samples_split=space['min_samples_split'],n_estimators=space['n_estimators'])\n",
    "    accuracy = cross_val_score(model,x_train,y_train,cv=5).mean()\n",
    "    return {'loss': -accuracy,'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af0bbc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 80/80 [10:47<00:00,  8.09s/trial, best loss: -0.7768759163001466]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 1,\n",
       " 'max_depth': 230.0,\n",
       " 'max_features': 0,\n",
       " 'min_samples_leaf': 0.017795696748113966,\n",
       " 'min_samples_split': 0.0035085856671450274,\n",
       " 'n_estimators': 2}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,space= space,algo=tpe.suggest,max_evals=80,trials=trials)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1fe3148",
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = {0:'entropy',1:'gini'}\n",
    "feat = {0:'auto', 1:'sqrt', 2:'log2', 3:None}\n",
    "est = {0: 10, 1: 50, 2: 300, 3: 750, 4: 1200, 5: 1300, 6: 1500}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06ca3345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gini\n",
      "auto\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print(crit[best['criterion']])\n",
    "print(feat[best['max_features']])\n",
    "print(est[best['n_estimators']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "456be749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017795696748113966"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best['min_samples_leaf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d7110736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[88 11]\n",
      " [29 26]]\n",
      "0.7402597402597403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.89      0.81        99\n",
      "           1       0.70      0.47      0.57        55\n",
      "\n",
      "    accuracy                           0.74       154\n",
      "   macro avg       0.73      0.68      0.69       154\n",
      "weighted avg       0.73      0.74      0.73       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_forest = RandomForestClassifier(criterion=crit[best['criterion']],max_depth=best['max_depth'],\n",
    "                                       max_features=feat[best['max_features']],min_samples_leaf=best['min_samples_leaf'],\n",
    "                                       min_samples_split=best['min_samples_split'],\n",
    "                                       n_estimators = est[best['n_estimators']])\n",
    "trained_forest.fit(x_train,y_train)\n",
    "y_predict = trained_forest.predict(x_test)\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "print(accuracy_score(y_test,y_predict))\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66a0a5d",
   "metadata": {},
   "source": [
    "## Genetic Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0bea2306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['sqrt', 'auto', 'log2'], 'max_depth': [10, 120, 230, 340, 450, 560, 670, 780, 890, 1000], 'min_samples_split': [1, 3, 4, 5, 7, 9], 'min_samples_leaf': [1, 2, 4, 6, 8], 'criterion': ['entropy', 'gini']}\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(200,2000,10)]\n",
    "max_features = ['sqrt','auto','log2']\n",
    "max_depth = [int(x) for x in np.linspace(10,1000,10)]\n",
    "min_samples_split = [1,3,4,5,7,9]\n",
    "min_samples_leaf = [1,2,4,6,8]\n",
    "\n",
    "random_grid = {'n_estimators':n_estimators,'max_features':max_features,'max_depth':max_depth,\n",
    "              'min_samples_split':min_samples_split,'min_samples_leaf':min_samples_leaf,\n",
    "              'criterion':['entropy','gini']}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d64fb735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/84 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.783454290807232\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.783454290807232\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.783454290807232\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.783454290807232\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.783454290807232\n",
      "\n",
      "Best pipeline: RandomForestClassifier(CombineDFs(input_matrix, input_matrix), criterion=gini, max_depth=450, max_features=log2, min_samples_leaf=6, min_samples_split=9, n_estimators=1400)\n",
      "[[87 12]\n",
      " [24 31]]\n",
      "0.7662337662337663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83        99\n",
      "           1       0.72      0.56      0.63        55\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.72      0.73       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tpc = TPOTClassifier(generations=5,population_size=24,offspring_size=12,verbosity=2,early_stop=12,\n",
    "                    config_dict={'sklearn.ensemble.RandomForestClassifier':random_grid},cv=4,scoring='accuracy')\n",
    "tpc.fit(x_train,y_train)\n",
    "y_predict = tpc.predict(x_test)\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "print(accuracy_score(y_test,y_predict))\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fa684b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36e7dd21",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e4557316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    classifier = trial.suggest_categorical('classifier',['RandoForest','SVC'])\n",
    "    \n",
    "    if classifier == \"RandomForest\":\n",
    "        n_estimators = trial.suggest_int(n_estimators,200,2000,10)\n",
    "        max_depth = int(trial.suggest_float('max_depth',10,100,log=True))\n",
    "        \n",
    "        clf = sklearn.ensemble.RandomForestClassifier(n_estimators=n_estimators,max_depth=max_depth)\n",
    "    else:\n",
    "        c = trial.suggest_float('svc_C',1e-10,1e10,log=True)\n",
    "        clf = sklearn.svm.SVC(C=c, gamma='auto')\n",
    "        \n",
    "    return sklearn.model_selection.cross_val_score(clf,x_train,y_train,n_jobs=-1,cv=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a2fafb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 18:45:28,813]\u001b[0m A new study created in memory with name: no-name-7f56e435-befa-42f1-9e37-19902fd48aa5\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:28,896]\u001b[0m Trial 0 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 1.7929960014216984e-08}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:28,991]\u001b[0m Trial 1 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 0.5949261016862427}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:29,065]\u001b[0m Trial 2 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 3.3178984551321806e-07}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:29,135]\u001b[0m Trial 3 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 2.2957299495622588e-09}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:29,231]\u001b[0m Trial 4 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 101232.63243440585}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:29,307]\u001b[0m Trial 5 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 1.4447961751966653e-05}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:29,401]\u001b[0m Trial 6 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 95257287.83303924}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:29,497]\u001b[0m Trial 7 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 86926507.87776342}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:29,589]\u001b[0m Trial 8 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 33554.20721386055}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:29,660]\u001b[0m Trial 9 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 2.8532521405129724e-06}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:29,759]\u001b[0m Trial 10 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 0.04982173667098368}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:29,861]\u001b[0m Trial 11 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 0.2532273959917898}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:29,966]\u001b[0m Trial 12 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 249.48007149267912}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:30,050]\u001b[0m Trial 13 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 1.018066393301846e-10}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:30,153]\u001b[0m Trial 14 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 0.001320938723636355}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:30,255]\u001b[0m Trial 15 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 97.73890955927601}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:30,354]\u001b[0m Trial 16 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 0.0016015725040876784}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:30,439]\u001b[0m Trial 17 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 0.0002983508393179304}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:30,546]\u001b[0m Trial 18 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 138.645620904426}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:30,629]\u001b[0m Trial 19 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 5.3270667588330234e-09}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:30,706]\u001b[0m Trial 20 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 8.146443700132311e-05}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:30,816]\u001b[0m Trial 21 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 34.94263371682596}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:30,897]\u001b[0m Trial 22 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 8.030713755502157e-09}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:30,974]\u001b[0m Trial 23 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 6.05946803299407e-08}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:31,051]\u001b[0m Trial 24 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 4.8383053149998184e-05}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:31,131]\u001b[0m Trial 25 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 1.460158870795906e-09}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:31,210]\u001b[0m Trial 26 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 1.3591881917076197e-07}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:31,288]\u001b[0m Trial 27 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 1.4775446174728073e-07}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:31,365]\u001b[0m Trial 28 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 1.338301293925504e-10}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:31,443]\u001b[0m Trial 29 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 3.227257304106811e-07}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:31,543]\u001b[0m Trial 30 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 0.01249421959126869}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:31,625]\u001b[0m Trial 31 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 1.5857677069990961e-10}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:31,710]\u001b[0m Trial 32 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 7.58516241082798e-07}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:31,814]\u001b[0m Trial 33 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 0.0232207368127425}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:31,893]\u001b[0m Trial 34 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 2.025171404959636e-06}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:31,995]\u001b[0m Trial 35 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 7.986693772437739}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:32,077]\u001b[0m Trial 36 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 8.195019734877011e-09}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:32,181]\u001b[0m Trial 37 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 7749.657122144103}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:32,296]\u001b[0m Trial 38 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 4939360.718807604}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 18:45:32,381]\u001b[0m Trial 39 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 3.1253260704101304e-08}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:32,458]\u001b[0m Trial 40 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 3.415090478255078e-05}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:32,543]\u001b[0m Trial 41 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 9.572705037482295e-10}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:32,623]\u001b[0m Trial 42 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 5.33035022140902e-08}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:32,701]\u001b[0m Trial 43 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 7.450779852288183e-06}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:32,785]\u001b[0m Trial 44 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 3.4122836150983514e-07}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:32,872]\u001b[0m Trial 45 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 9.955023686036585e-10}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:32,953]\u001b[0m Trial 46 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 5.546085136728262e-10}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:33,031]\u001b[0m Trial 47 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 1.701634215926096e-07}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:33,115]\u001b[0m Trial 48 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 1.3848368271439805e-06}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:33,200]\u001b[0m Trial 49 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 2.045231846458183e-08}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:33,296]\u001b[0m Trial 50 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 0.006597578861288113}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:33,381]\u001b[0m Trial 51 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 3.1769029793627485e-10}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:33,465]\u001b[0m Trial 52 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 5.725373611531789e-07}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:33,552]\u001b[0m Trial 53 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 4.1768484666183276e-10}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:33,647]\u001b[0m Trial 54 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 0.0788119597797568}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:33,750]\u001b[0m Trial 55 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 1.3043449305029855}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:33,854]\u001b[0m Trial 56 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 0.01111415811778331}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:33,929]\u001b[0m Trial 57 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 0.00033495150211509484}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:34,036]\u001b[0m Trial 58 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 2.9061812888848677}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:34,139]\u001b[0m Trial 59 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 739.5895511742299}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:34,255]\u001b[0m Trial 60 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 8.542530019189357}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:34,361]\u001b[0m Trial 61 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 1965850201.8218536}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:34,467]\u001b[0m Trial 62 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 198754.5091577238}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:34,573]\u001b[0m Trial 63 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 338116.30905823834}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:34,674]\u001b[0m Trial 64 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 2454544.3694959674}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:34,777]\u001b[0m Trial 65 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 36728904.115349546}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:34,879]\u001b[0m Trial 66 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 851.5653115925968}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:34,987]\u001b[0m Trial 67 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 4290.710479376206}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:35,076]\u001b[0m Trial 68 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 5.298325856548809e-09}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:35,165]\u001b[0m Trial 69 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 1.3402241113162249e-08}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:35,246]\u001b[0m Trial 70 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 1.0112101275954881e-05}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:35,326]\u001b[0m Trial 71 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 2.092581536699633e-09}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:35,409]\u001b[0m Trial 72 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 3.5119795976136e-06}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:35,491]\u001b[0m Trial 73 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 9.863022196573322e-07}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:35,577]\u001b[0m Trial 74 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 3.4934285276499775e-10}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:35,663]\u001b[0m Trial 75 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 2.053412701500862e-08}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:35,789]\u001b[0m Trial 76 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 0.10835250084457229}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:35,892]\u001b[0m Trial 77 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 0.004844883920960821}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-12 18:45:36,000]\u001b[0m Trial 78 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 0.06299447265923837}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:36,107]\u001b[0m Trial 79 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 0.40699626057680205}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:36,187]\u001b[0m Trial 80 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 0.0002551884040762923}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:36,289]\u001b[0m Trial 81 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 1.2273852994665901}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:36,391]\u001b[0m Trial 82 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 5.266258853004559}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:36,503]\u001b[0m Trial 83 finished with value: 0.6530926191614858 and parameters: {'classifier': 'SVC', 'svc_C': 0.0012719188039755727}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:36,615]\u001b[0m Trial 84 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 27.84885808345414}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:36,719]\u001b[0m Trial 85 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 2.0539084846446602}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:36,821]\u001b[0m Trial 86 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 0.2114382525675456}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:36,930]\u001b[0m Trial 87 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 5891216723.324685}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:37,043]\u001b[0m Trial 88 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 107900.24812474233}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:37,156]\u001b[0m Trial 89 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 260675.17046749927}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:37,255]\u001b[0m Trial 90 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 4062004.277793083}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:37,367]\u001b[0m Trial 91 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 500660308.62429917}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:37,476]\u001b[0m Trial 92 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 1137.0660265324207}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:37,587]\u001b[0m Trial 93 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 2169963.276230995}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:37,691]\u001b[0m Trial 94 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 8328.804449662583}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:37,794]\u001b[0m Trial 95 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 36624505.951066606}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:37,903]\u001b[0m Trial 96 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 573508.5554810091}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:38,017]\u001b[0m Trial 97 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 41172658.86418258}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:38,128]\u001b[0m Trial 98 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 30145.351686639224}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n",
      "\u001b[32m[I 2021-10-12 18:45:38,213]\u001b[0m Trial 99 finished with value: 0.6530926191614858 and parameters: {'classifier': 'RandoForest', 'svc_C': 6.204241827862305e-09}. Best is trial 0 with value: 0.6530926191614858.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6530926191614858\n",
      "Best Hyperparameters: {'classifier': 'SVC', 'svc_C': 1.7929960014216984e-08}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective,n_trials=100)\n",
    "\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy:',trial.value)\n",
    "print('Best Hyperparameters:',trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a6698c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=0, values=[0.6530926191614858], datetime_start=datetime.datetime(2021, 10, 12, 18, 45, 28, 817705), datetime_complete=datetime.datetime(2021, 10, 12, 18, 45, 28, 896636), params={'classifier': 'SVC', 'svc_C': 1.7929960014216984e-08}, distributions={'classifier': CategoricalDistribution(choices=('RandoForest', 'SVC')), 'svc_C': LogUniformDistribution(high=10000000000.0, low=1e-10)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=0, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "21f0962e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': 'SVC', 'svc_C': 1.7929960014216984e-08}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a738648f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85 14]\n",
      " [24 31]]\n",
      "0.7532467532467533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82        99\n",
      "           1       0.69      0.56      0.62        55\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.71      0.72       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# take following parameters accordingly above results\n",
    "rfc=RandomForestClassifier(n_estimators=330,max_depth=330)\n",
    "rfc.fit(x_train,y_train)\n",
    "y_predict = rfc.predict(x_test)\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "print(accuracy_score(y_test,y_predict))\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca1a98d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31e08f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106da9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5949ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f29831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbe54ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
